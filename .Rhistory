modelFit_non = train(train$training.diagnosis ~ ., method = "glm", data = train)
confusionMatrix(test$testing.diagnosis, predict(modelFit_non, test))
train1 = training[grep("^IL", colnames(training))]
head(train1)
dim(train1)
preProc = preProcess(train1[,-13],method = "pca", thresh = .8)
preProc$rotation
preProc = preProcess(train1[,-13],method = "pca",pcaComp = 7)
trainPC = predict(preProc,train1[,-13])
testPC = predict(preProc,test1[,-13])
modelFit = train(train$training.diagnosis ~ ., method = "glm", data = trainPC)
confusionMatrix(test$testing.diagnosis, predict(modelFit, testPC))
modelFit_non = train(train$training.diagnosis ~ ., method = "glm", data = train)
confusionMatrix(test$testing.diagnosis, predict(modelFit_non, test))
install.packages("ElemStatLearn")
library(ElemStatLearn); data(ozone, package = "ElemStatLearn")
ozone1 = ozone[order(ozone$ozone),]
ozone1 - ozone
head(ozone)
head(ozone1)
ozone1
dim(ozone);dim(ozone1)
head(ozone)
head(ozone1)
sample(155,replace=T)
sample(1,155,replace=T)
sample(155,2,replace=T)
summary(ozone1)
ozone = 1:155
data(ozone, package = "ElemStatLearn")
data.frame(ozone = 1:155)
library(caret)
args(bagContro)
args(bagControl)
?bagControl
data(iris); library(ggplot2)
inTrain = createDataPartition(y = iris$SPecies, p =.7, list=F)
training= iris[inTrain,]
testing = iris[-inTrain,]
inTrain = createDataPartition(y = iris$SPecies, p =.7, list=F)
inTrain = createDataPartition(y = iris$Species, p =.7, list=F)
training= iris[inTrain,]
testing = iris[-inTrain,]
modFit = train(Species~., data =training, method = 'rf', prox =T)
modFit = train(Species~., data =training, method = 'rf', prox =T)
modFit
modFit = train(Species~., data =training, method = 'rf')
modFit
modFit$finalModel
head(iris)
plot(getTree(modFit$finalModel,k=2))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret);
seg = segmentationOriginal
summary(seg)
inTrain = createDataPartition(seg$Case, p = ,7, list =F)
training = seg[inTrain,]; testing = seg[-inTrain,]
set.seed(125)
cart = train(Case ~ ., method = "rpart", data = training)
print(cart$finalModel)
?cart
??cart
cart = train(Case ~ ., method = "rpart", data = training)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
data(olive)
data(olive)
olive
head(olive)
olive = olive[,-1]
print(cart$finalModel)
cart
print(cart$finalModel)
head(seg$TotalIntench2)
Case
seg$TotalIntench2
seg$PerimStatusCh1
head(seg$PerimStatusCh1)
sum(seg$PerimStatusCh1==2
sum(seg$PerimStatusCh1==2)
sum(seg$PerimStatusCh1==2)
summary(seg)
seg[seg$PerimStatusCh1==2,]
seg[seg$PerimStatusCh1==2,"TotalIntenCh2 "]
seg[seg$PerimStatusCh1==2,"TotalIntenCh2"]
print(cart$finalModel)
summary(seg$Case)
cart = train(Class ~ ., method = "rpart", data = training)
print(cart$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(cart$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(cart$finalModel)
print(cart$finalModel)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
library(caret);
library(rattle)
library(AppliedPredictiveModeling)
library(pgmm)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
summary(SAheart)
fitFA = train(chd ~., data= trainSA, method = "glm",family="binomial")
fitFA = train(chd ~ age + alcohol + obesity + tabacco + typea +ldl, data= trainSA, method = "glm",family="binomial")
fitFA = train(chd ~ age + alcohol + obesity + tobacco + typea +ldl, data= trainSA, method = "glm",family="binomial")
missClass = function(
values,prediction)
{sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA[,"chd"],predict(fitFA,testSA))
names(fitFA)
fitFA$results
fitFA$pred
names(fitFA$finalModel)
fitFA$finalModel$fitted.values
missClass(testSA[,"chd"],fitFA$finalModel$fitted.values)
missClass(trainSA[,"c"],predict(fitFA,trainSA))
missClass(trainSA[,"c"],fitFA$finalModel$fitted.values)
missClass(trainSA[,"chd"],fitFA$finalModel$fitted.values)
data(olive)
olive = olive[,-1]
head(olive)
colMeans(olive)
t(colMeans(olive))
?t
newdata = as.data.frame(t(colMeans(olive)))
print(fitOL$finalModel)
fitOL = train(Area ~ ., method = "rpart", data = training)
fitOL = train(Area ~ ., method = "rpart", data = olive)
print(fitOL$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
newdata
data(segmentationOriginal)
seg = segmentationOriginal
inTrain = createDataPartition(seg$Case, p = ,7, list =F)
training = seg[inTrain,]; testing = seg[-inTrain,]
set.seed(125)
cart = train(Class ~ ., method = "rpart", data = training)
print(cart$finalModel)
predict(fitOL,newdata)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
fit <- train(y~., data=vowel.train, method = "rf")
imps <- varImp(fit)
order(imps)
imps
?accurancy
??accurancy
install.packages("quantmod")
??accurancy
?accurancy
library(quantmod)
?accurancy
install.packages("forecast")
?accurancy
??accurancy
library(forecast)
?accurancy
?accuracy
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn); library(caret)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
fit1 = train( y ~ ., data = VOwel.train, method = "rf")
fit2 = train( y ~ ., data = VOwel.train, method = "gbm", verbose = F)
fit1 = train( y ~ ., data = vowel.train, method = "rf")
fit2 = train( y ~ ., data = vowel.train, method = "gbm", verbose = F)
fit1
fit$finalModel
fit1$finalModel
preds1 = predict(fit1, vowel.test)
preds2 = predict(fit2, vowel.test)
confusionMatrix(preds2, vowel.test)
confusionMatrix(preds1, vowel.test)
confusionMatrix(preds1, vowel.test$y)
summary(preds)
summary(preds1)
preds1
View(preds1)
confusionMatrix(preds2, vowel.test$y)
confusionMatrix(vowel.test$y,preds1)
confusionMatrix(vowel.test$y,preds2)
rf_ac = sum(preds1 == vowel.test$y)/length(preds1)
rf_ac
set.seed(33833)
rf_ac = sum(preds2 == vowel.test$y)/length(preds2)
rf_ac
gbm_ac = sum(preds2 == vowel.test$y)/length(preds2)
agree = vowel.test[preds1 == preds2,]
preds3 = predict(fit1, agree)
ag_ac = sum(preds3 == vowel.test$y)/length(preds3)
ag_ac = sum(preds3 == agree$y)/length(preds3)
ag_ac
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433 )
str(training)
rf_fit = train(diagnosis, data = training, method = "rf")
gbm_fit = train(diagnosis, data = training, method = "gbm")
lda_fit = train(diagnosis, data = training, method = "lda")
rf_fit = train(diagnosis~., data = training, method = "rf")
gbm_fit = train(diagnosis~., data = training, method = "gbm")
lda_fit = train(diagnosis~., data = training, method = "lda")
rf_pred = predict(rf_fit, testing)
gbm_pred = predict(gbm_fit, testing)
lda_pred = predict(lda_fit, testing)
data.frame(rf_pred,gbm_pred,lda_pred,diagnosis = testing$diagnosis)
predStack = data.frame(rf_pred,gbm_pred,lda_pred,diagnosis = testing$diagnosis)
confusionMatrix(rf_pred,testing$y)
confusionMatrix(rf_pred,testing$diagnosis)
names(confusionMatrix(rf_pred,testing$diagnosis))
confusionMatrix(rf_pred,testing$diagnosis)$overall
confusionMatrix(rf_pred,testing$diagnosis)$overall
confusionMatrix(rf_pred,testing$diagnosis)$overall
confusionMatrix(rf_pred,testing$diagnosis)$overall
confusionMatrix(rf_pred,testing$diagnosis)$overall
confusionMatrix(gbm_pred,testing$diagnosis)$overall
confusionMatrix(lda_pred,testing$diagnosis)$overall
stack_fit = train(diagnosis~., data = predStack, mothod = "rf")
stack_pred = predict(stack_fit, testing)
confusionMatrix(stack_pred,testing$diagnosis)$overall
seed
?set.seed
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model = train(CompressiveStrength ~ ., method = 'lasso', data = training)
plot(model$finalModel)
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
plot.enet(model$finalModel, xvar="penalty", use.color=T)
library(lubridate)  # For year() function below
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("G:/Onedrive/courses/ml/WEEK 3/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
summary(training)
View(training)
View(tstrain)
library(forecast)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(AppliedPredictiveModeling); library(caret)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(AppliedPredictiveModeling); library(caret);library(e1071)
model = svm(CompressiveStrength ~ ., data = training)
View(concrete)
model
pred = predict(model,testing)
confusionMatrix(pred,testing$CompressiveStrength)
length(pred)
dim(testing)
confusionMatrix(testing$CompressiveStrength,pred)
pred
testing$CompressiveStrength
sqrt(sum((pred - true)^2))
true = testing$CompressiveStrength
sqrt(sum((pred - true)^2))
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling); library(caret);library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model = svm(CompressiveStrength ~ ., data = training)
pred = predict(model,testing)
true = testing$CompressiveStrength
sqrt(sum((pred - true)^2))
library(forecast); library(quantmod)
library(lubridate)  # For year() function below
dat = read.csv("G:/Onedrive/courses/ml/WEEK 3/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model = bats(tstrain)
model
model = bats(tstrain)
plot(tstrain)
pred = forecast(model, level = c(95), h = dim(testing)[1])
accuracy(pred, testing)
accuracy(pred, testing$visitsTumblr)
names(pred)
true = testing$visitsTumblr
sum(true<pred$upper & true>pred$lower)/length(true)
accuracy(pred, true)
accuracy(pred, true)[2]
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling); library(caret);library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model = svm(CompressiveStrength ~ ., data = training)
model
pred = predict(model,testing)
true = testing$CompressiveStrength
accuracy(pred, true)[2]
sqrt(sum((pred - true)^2))
sqrt(mean((pred - true)^2))
### ques 4-1
library(ElemStatLearn); library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
fit1 = train( y ~ ., data = vowel.train, method = "rf")
fit2 = train( y ~ ., data = vowel.train, method = "gbm", verbose = F)
pmltrain = read.csv("E:/FX/pml/pml-training.csv")
pmltest = read.csv("E:/FX/pml/pml-testing.csv")
View(pmltest)
View(pmltrain)
summary(pmltrain);summary(pmltest)
summary(pmltest)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers = rep("A", 20)
pml_write_files(answers)
setwd("E:/FX/pml")
pml_write_files(answers)
pml_write_files(answers)
answers = rep("A", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
summary(pmltrain)
names(pmltrain)
152/4
View(pmltest)
summary(pmltest)
pmltrain$classe = factor(pmltrain$classe)
pmltest$classe = factor(pmltest$classe)
pmltest$classe = factor(pmltest$classe)
inTrain = createDataPatition(pmltrain$classe, p = 3/4)[[1]]
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
library(caret); library(forecast)
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
is.na(pmltrain)
colMeans(is.na(pmltrain))
colMeans(is.na(pmltrain))<.5
which(colMeans(is.na(pmltrain))<.5)[[1]]
which(colMeans(is.na(pmltrain))<.5)
names(which(colMeans(is.na(pmltrain))<.5))
View(which(colMeans(is.na(pmltrain))<.5))
which(colMeans(is.na(pmltrain))<.5)[,2]
which(colMeans(is.na(pmltrain))<.5)$x
pmltrain[,'which(colMeans(is.na(pmltrain))<.5)']
pmltrain[,which(colMeans(is.na(pmltrain))<.5)]
pmltrain[2,which(colMeans(is.na(pmltrain))<.5)]
length(pmltrain[2,which(colMeans(is.na(pmltrain))<.5)])
View(pmltrain[2,which(colMeans(is.na(pmltrain))<.5)])
View(pmltrain[2,which(colMeans(is.na(pmltrain))<.3)])
View(pmltrain[2,which(colMeans(is.na(pmltrain))<.1)])
sum(is.na(plmtrain[2,]))
sum(is.na(pmltrain[2,]))
View(pmltrain[1:10,which(colMeans(is.na(pmltrain))<.5)])
sum(is.na(pmltrain["kurtosis_roll_dumbbell",]))
pmltrain["kurtosis_roll_dumbbell",1]
is.na(pmltrain["kurtosis_roll_dumbbell",1])
sum(is.na(pmltrain["kurtosis_roll_dumbbell",]))/dim(pmltrain)[1]
is.na(pmltrain['kurtosis_roll_dumbbell',])
mean(is.na(pmltrain['kurtosis_roll_dumbbell',]))
sum(is.na(pmltrain['kurtosis_roll_dumbbell',]))
sum(is.na(pmltrain[,'kurtosis_roll_dumbbell']))
mean(is.na(pmltrain[,'kurtosis_roll_dumbbell']))
is.na(pmltrain[1,'kurtosis_roll_dumbbell'])
pmltrain[1,'kurtosis_roll_dumbbell']
head(summary(pmltrain))
rm(list = ls())
library(caret); library(forecast)
pmltrain = read.csv("E:/FX/pml/pml-training.csv")
pmltest = read.csv("E:/FX/pml/pml-testing.csv")
pmltrain$classe = factor(pmltrain$classe)
names(pmltrain)
head(colMeans(is.na(pmltrain)))
head(colMeans(is.na(pmltrain)),20)
sum(colMeans(is.na(pmltrain)),20)>0)
sum(colMeans(is.na(pmltrain))>0)
pmltrain[1,"kurtosis_roll_belt"]
pmltrain[,"kurtosis_roll_belt"]
summary(pmltrain[,"kurtosis_roll_belt"])
class(pmltrain[,"kurtosis_roll_belt"])
index = which(colMeans(is.na(pmltest))<.5)
index
length(index)
class(pmltrain$user_name)
class(pmltrain$raw_timestamp_part_1)
class(pmltrain$cvtd_timestamp)
index = index[,-c(1,4,5,6,7,60)]
index = index[-c(1,4,5,6,7,60)]
index
length(index)
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
training = pmltrain[inTrain,index]
length(names(training))
testing = pmltrain[-inTrain,index]
set.seed(123)
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
sum(is.na(training))
rfFit = train(classe ~ ., data = training, preProcess = c("center", "scale"), method = "rf",  )
index = which(colMeans(is.na(pmltest))<.5)
index
View(pmltrain)
summary(pmltrain)
index$classe
View(index)
index = which(colMeans(is.na(pmltest))<.5)
index = index[-c(1,4,5,6,7)]   # 54 variables in total
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
rfFit = train(classe ~ ., data = training, preProcess = c("center", "scale"), method = "rf",  )
rfFit
sapply(class,training)
?sapply
sapply(training,class)
dim(training)
View(pmltrain)
index = which(colMeans(is.na(pmltest))<.5)
index = index[-c(1,3,4,5,6,7)]   # 54 variables in total
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
rfFit = train(classe ~ ., data = training, method = "rf")
index = which(colMeans(is.na(pmltest))<.5)
index = index[-c(1,2,3,4,5,6,7)]   # 54 variables in total
index
inTrain = createDataPartition(pmltrain$classe, p = 3/4)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
rfFit = train(classe ~ ., data = training, method = "rf")
summary(training)
dim(training)
rfFit = train(classe ~ ., data = training, method = "rf")
inTrain = createDataPartition(pmltrain$classe, p = .3)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
rfFit = train(classe ~ ., data = training, method = "rf")
fit = rpart (classe ~., data=training, method="class", control=rpart.control (minsplit=10, cp=0, xval=1))
??rpart
library(rpart)
fit = rpart (classe ~., data=training, method="class", control=rpart.control (minsplit=10, cp=0, xval=1))
gbmFit = train(classe~ ., data= training, method = "gbm")
gbmFit = train(classe~ ., data= training, method = "gbm", verbose = F)
inTrain = createDataPartition(pmltrain$classe, p = .6)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
