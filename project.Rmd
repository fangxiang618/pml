---
title: "pml-project-fx"
author: "Xiang Fang"
date: "Sunday, May 24, 2015"
output: html_document
---
The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing 1)how you built your model, 2)how you used cross validation, 3)what you think the expected out of sample error is, and 4)why you made the choices you did. 5)You will also use your prediction model to predict 20 different test cases


load the data and explore a little
```{r}
rm(list = ls())
library(caret); library(forecast)
library(doMC)
registerDoMC(cores = 5)
pmltrain = read.csv("E:/FX/pml/pml-training.csv")
pmltest = read.csv("E:/FX/pml/pml-testing.csv")
pmltrain$classe = factor(pmltrain$classe)
names(pmltrain)
#summary(pmltrain); summary(pmltest)
```
I found there are mainly 4 sensors: belt, arm, dumbbell and forearm. And for each sensor, they test roll, pitch and yaw, including their statistical attribute (e.g.  kuro, skew, max, min, amplitude, avg, std, var). They also have x, y, z for each gyros, accel and magnet wrt 4 sensors plus and total acceleration and its var. And almost all of them are qualitative.
And some features are only available when new window == 1.
Note that there are lots of variables dominated by NA's and also in pmltest dataset.
So my first step to clean the data is to do with these NA's.

Detect the precentage of NA's, showing partly. And extract the variable whose NA percentage is less than 50%. Results show R recognize some variables as factor when there are too few non-NAs, particularly, in the case of some statistical features. 
SO here is a big trade-off-- when observing the pmltest dataset, I found only about 58 non-NA variables. Is it too reckless to just give up all other variables? Considering the fact that in pmltest dataset only (new window ==0) exists and the statistical features are actually derivatives of the original data(although these are not sufficient to prove), I decided to try model with only these 50 more variables. That is, 52 original variables plus user_name and one time measure.

```{r}
head(colMeans(is.na(pmltrain)),20)
index = which(colMeans(is.na(pmltest))<.5)
index = index[-c(1,2,3,4,5,6,7)]   # 54 variables in total
```

create data slicing: train set and test set. And do some basic prepocessing (without imputing data since there are no NAs at all now).
```{r}
set.seed(123)
inTrain = createDataPartition(pmltrain$classe, p = .6)[[1]]
training = pmltrain[inTrain,index]
testing = pmltrain[-inTrain,index]
#sum(is.na(training)) == 0
```

try to fit some models with standardization using the method of random forest, gbm and decision tree with rpart package.
Obviously, it tooks me really long time to run the code, 
```{r}
library(rpart)
treeFit = rpart (classe ~., data=training, method="class", control=rpart.control (minsplit=10, cp=0, xval=1))
gbmFit = train(classe~ ., data= training, method = "gbm", verbose = F)
rfFit = train(classe~ ., data = training, method = "rf",trControl=trainControl(method="cv",number=5), prox = T, allowParallel=T)
```

Then have a look at the results
```{r}
varImp(rfFit)
varImp(gbmFit)

trPred = predict(treeFit, testing)
gbmPred = predict(gbmFit, testing)
rfPred = predict(rfFit, testing)

confusionMatrix(trPred,testing$classe)
confusionMatrix(gbmPred,testing$classe)
confusionMatrix(rfPred,testing$classe)

```